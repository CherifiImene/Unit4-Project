{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcBqRLqzMULW"
      },
      "source": [
        "# Unit 4 Project\n",
        "After understanding how neural networks work, implementing some basic architectures using deep learning frameworks, and learning about some advanced techniques to help enhance our neural networks' models results, it's time to apply what you learned! So let's start\n",
        "\n",
        "## Project Overview \n",
        "In this project, you will build a neural network model to classify images from CIFAR 10 dataset. \n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 color images of 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. [source](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "Unlike the previous projects, there will be no code cells to fill, the only task you have is to build the best possible model using the techniques you learned about in this unit. But we will guide you with some directives.\n",
        "\n",
        "You will have enough guidance throughout the project and your work will be reviewed and graded by a teacher assistant. You can also reach out to the TA via slack whenever you feel you are stuck.\n",
        "\n",
        "## Some guidelines\n",
        "- Please use text cells to write the questions' answers in a good way.\n",
        "- Don't forget to save the different models you tested so you will be able to report the different results you got and the impact of the different techniques you tested later.\n",
        "\n",
        "## Getting started\n",
        "- In case you don't have a GPU, it is recommended that you use google colab. Start by cloning this repository, then open [google colab](https://colab.research.google.com/), click on File > Upload notebook, and finally upload the ```.ipynb``` file from the repository you have just cloned! Don't forget to change the runtime to GPU. If you want to work in your local environment just open it using jupyter notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLavLevW45rD"
      },
      "source": [
        "## Dataset \n",
        "\n",
        "1.   Load the dataset (**hint**: it's available here https://keras.io/api/datasets/)\n",
        "2.   Display few images of each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIDwu9xQKDgj",
        "outputId": "88642583-4a08-4b4d-88e2-12b7f7c5f0fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "COiq2EgT13Ux"
      },
      "outputs": [],
      "source": [
        "# import all necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets.cifar10 import load_data\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.regularizers import L1, L2, L1L2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# For data augmentation\n",
        "from keras.layers import Rescaling, RandomFlip, RandomRotation\n",
        "from keras.layers import RandomContrast, RandomZoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7D9q0qVMj98",
        "outputId": "1dceb9d1-e29f-4ced-d329-c2b8e67df357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test)= load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6jEamrofSig"
      },
      "outputs": [],
      "source": [
        "def display_images(images,labels):\n",
        "  fig = plt.figure(figsize=(18,15))\n",
        "\n",
        "  labels_dict = {\n",
        "    0: \"airplane\",\n",
        "    1 :\"automobile\",\n",
        "    2 :\t\"bird\",\n",
        "    3 :\t\"cat\",\n",
        "    4 :\t\"deer\",\n",
        "    5 :\t\"dog\",\n",
        "    6 :\t\"frog\",\n",
        "    7 :\t\"horse\",\n",
        "    8 :\t\"ship\",\n",
        "    9 :\t\"truck\"\n",
        "}\n",
        "  def get_image_indices(labels,labels_dict):\n",
        "    indices = []\n",
        "    for label in labels_dict.keys():\n",
        "      all_indices = np.where(y_train == label)\n",
        "      indices.extend(all_indices[0][:2])\n",
        "    return indices\n",
        "  indices = get_image_indices(labels,labels_dict)\n",
        "  for i in range(20):\n",
        "    fig.add_subplot(4,5,i+1)\n",
        "\n",
        "    plt.imshow(images[indices[i]])\n",
        "    plt.title(labels_dict[labels[indices[i],0]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "id": "xBbhRdf5ZKf1",
        "outputId": "6cdcddbc-6d9c-4718-a767-fcfd9efe19ca"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1296x1080 with 20 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Display few images of each class\n",
        "display_images(x_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmIZ1vTp6pDZ"
      },
      "source": [
        "## Baseline Model\n",
        "\n",
        "1.   Build a basline model using only dense layers, activation function of your choice, and the adapted cost function for this problem.\n",
        "2.   Train and evaluate your model\n",
        "3.   Analyze the result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0qKs1Mg9wAx3"
      },
      "outputs": [],
      "source": [
        "def create_model(optimizer=Adam(),basic=False,BN_before=True,dropout_rate=0.3,nb_layers=3,nb_neurones=[132,100,10],activation_functions=['relu','relu','softmax'],\n",
        "                 weight_initializations=[\"he_normal\",\"he_normal\",\"he_normal\"],regularizer=None, data_augmentation=None):\n",
        "  \n",
        "  assert nb_layers == len(nb_neurones),f'You should provide number of neurones for {nb_layers}, you provided for {len(nb_neurones)} layers'\n",
        "  assert nb_layers == len(activation_functions),f'You should provide activation functions for each layer, you provided only for {len(activation_functions)} layers'\n",
        "  assert nb_layers == len(weight_initializations),f'You should provide initialization method for each layer, you provided only for {len(weight_initializations)} layers'\n",
        "\n",
        "  if basic :\n",
        "    model = Sequential([\n",
        "                      Flatten(input_shape=(32, 32,3)) ])\n",
        "    for layer in range(nb_layers):\n",
        "      model.add(Dense(nb_neurones[layer],\n",
        "                        activation= activation_functions[layer],\n",
        "                        kernel_initializer=weight_initializations[layer]\n",
        "                        )\n",
        "      )\n",
        "  else:\n",
        "    model = Sequential()\n",
        "    if data_augmentation != None :\n",
        "      model.add(data_augmentation)\n",
        "    model.add(Flatten(input_shape=(32, 32,3)))\n",
        "\n",
        "    for layer in range(nb_layers):\n",
        "      if activation_functions[layer] == \"lrelu\":\n",
        "        if BN_before:\n",
        "          model.add(BatchNormalization())\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(Dense(nb_neurones[layer],\n",
        "                        activation=LeakyReLU(),\n",
        "                        kernel_initializer=weight_initializations[layer],\n",
        "                        kernel_regularizer=regularizer\n",
        "                        )\n",
        "        )\n",
        "        if not BN_before:\n",
        "          model.add(BatchNormalization())\n",
        "      else:\n",
        "        if BN_before:\n",
        "          model.add(BatchNormalization())\n",
        "        model.add(Dropout(rate=dropout_rate))\n",
        "        model.add(Dense(nb_neurones[layer],\n",
        "                        activation=activation_functions[layer],\n",
        "                        kernel_initializer=weight_initializations[layer],\n",
        "                        kernel_regularizer=regularizer)\n",
        "        )\n",
        "        if not BN_before:\n",
        "          model.add(BatchNormalization())\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=SparseCategoricalCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj0D8kHF9_K3",
        "outputId": "d0b701b8-ca35-4e85-8ee4-f54ba6c1a1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 6s 4ms/step - loss: 17.5404 - accuracy: 0.1974\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.4122 - accuracy: 0.2413\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1740 - accuracy: 0.2558\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2127 - accuracy: 0.2400\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3700 - accuracy: 0.1009\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0983\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.0983\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.0995\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.0985\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3031 - accuracy: 0.0992\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0988\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.1009\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0997\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3030 - accuracy: 0.0985\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 2.3031 - accuracy: 0.0992\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0975\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0960\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3030 - accuracy: 0.0986\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.3029 - accuracy: 0.0990\n",
            "INFO:tensorflow:Assets written to: ./my_models/basic_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "model = create_model(basic=True)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "model.save('./my_models/basic_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ky6D9hhTu--",
        "outputId": "7f4e9ef7-5fb1-4b6f-e3b6-7e24c16a6b62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 2.3042 - accuracy: 0.1000 - 905ms/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.10000000149011612\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLfG2iPobTIK"
      },
      "source": [
        "**Analysis :**\n",
        "As we can see the loss started decreasing at a certain point then it stagnned in the same value 2.3030. The accuracy however was decreasing instead of increasing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvygWbNy-BxD"
      },
      "source": [
        "## Accelerating the training\n",
        "\n",
        "1.   Add batch normalization layers to your network in order to accelerate the training. Start with adding batch norm layer before each of your activation layers.\n",
        "2.   Analyze the new results\n",
        "3.   Change the position of the batch norm layers so they will be after the activation layers. Compare the results.\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNaAVBN4-Ai4",
        "outputId": "fade511d-da4f-41a6-e117-d2f79abafb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 12s 6ms/step - loss: 1.9349 - accuracy: 0.3237\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6928 - accuracy: 0.3951\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6326 - accuracy: 0.4176\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5932 - accuracy: 0.4328\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5604 - accuracy: 0.4433\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5374 - accuracy: 0.4525\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5207 - accuracy: 0.4579\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5039 - accuracy: 0.4622\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4831 - accuracy: 0.4702\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4770 - accuracy: 0.4746\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4590 - accuracy: 0.4810\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4560 - accuracy: 0.4809\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4392 - accuracy: 0.4864\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4367 - accuracy: 0.4898\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4263 - accuracy: 0.4917\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4248 - accuracy: 0.4928\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4164 - accuracy: 0.4967\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4124 - accuracy: 0.4978\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4070 - accuracy: 0.5023\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4012 - accuracy: 0.5018\n",
            "INFO:tensorflow:Assets written to: ./my_models/basic+BN_before_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "model = create_model(BN_before=True)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "model.save('./my_models/basic+BN_before_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX6PUjtVemz5",
        "outputId": "ce93cb68-95a5-4ce0-c896-9e1283997c87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.2818 - accuracy: 0.5438 - 1s/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.5437999963760376\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvsxr9bdeqlm"
      },
      "source": [
        "**Analysis :**\n",
        "After adding batch normalization before each Dense layer, the accuracy improved significantly from 0.32 to 0.5 during training.\n",
        "\n",
        "The Accuracy in validation data also improved to reach 0.54. Despite this improvement, the value of accuracy is still low."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMFXLtnQhYi2"
      },
      "source": [
        "### Changing the position of BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2twldC-whhHB",
        "outputId": "c5e55530-1032-4cf6-83d0-cbf4e7dc880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 2.1314 - accuracy: 0.2839\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.9809 - accuracy: 0.3197\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9114 - accuracy: 0.3324\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8733 - accuracy: 0.3372\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8496 - accuracy: 0.3467\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8200 - accuracy: 0.3545\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8108 - accuracy: 0.3574\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7974 - accuracy: 0.3606\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7877 - accuracy: 0.3651\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7798 - accuracy: 0.3673\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7702 - accuracy: 0.3721\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7666 - accuracy: 0.3713\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7644 - accuracy: 0.3708\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7533 - accuracy: 0.3779\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7487 - accuracy: 0.3784\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7465 - accuracy: 0.3787\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7417 - accuracy: 0.3810\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7334 - accuracy: 0.3822\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7330 - accuracy: 0.3819\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7311 - accuracy: 0.3840\n",
            "INFO:tensorflow:Assets written to: ./my_models/basic+BN_after_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "model = create_model(BN_before=False)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "model.save('./my_models/basic+BN_after_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdPZsdV2ivS2",
        "outputId": "41dcb7ec-023e-4465-dd6d-4b175ba5a8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.5565 - accuracy: 0.4545 - 1s/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.4544999897480011\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZFjKy4Ki6UH"
      },
      "source": [
        "**Analysis**\n",
        "\n",
        "As we can see adding the BatchNormalization Layer after each Dense layer, doesn't give as much good result as adding it before each dense layer (0.45 < 0.54)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYXf6uM6DJ1a"
      },
      "source": [
        "## Reducing the overfitting \n",
        "\n",
        "\n",
        "1.   Apply the dropout technique to reduce the overfitting your model is suffering from\n",
        "2.   Try different dropout rates \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2er70cnXDIqI",
        "outputId": "ada85843-d3f5-46a6-95fb-b10dd0ecc987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 11s 6ms/step - loss: 1.8552 - accuracy: 0.3479\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6396 - accuracy: 0.4158\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5678 - accuracy: 0.4404\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5223 - accuracy: 0.4589\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4881 - accuracy: 0.4692\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4613 - accuracy: 0.4796\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4380 - accuracy: 0.4881\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4195 - accuracy: 0.4948\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4028 - accuracy: 0.5009\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3876 - accuracy: 0.5076\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3717 - accuracy: 0.5124\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3610 - accuracy: 0.5140\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3481 - accuracy: 0.5204\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3439 - accuracy: 0.5193\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3337 - accuracy: 0.5264\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3309 - accuracy: 0.5242\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3173 - accuracy: 0.5305\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3098 - accuracy: 0.5350\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3056 - accuracy: 0.5352\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2924 - accuracy: 0.5402\n",
            "INFO:tensorflow:Assets written to: ./my_models/dropout_model_rate_0.2/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.2473 - accuracy: 0.5574 - 1s/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.5573999881744385\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "model = create_model(dropout_rate=0.2)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "\n",
        "model.save('./my_models/dropout_model_rate_0.2')\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_G-21FyorZX"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "The accuracy in the test set is better than the accuracy during training (0.55 > 0.54) which proves that the overfitting has been reduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeqfp6FVqhqk",
        "outputId": "ffe62065-e254-45c6-c6b5-61730658b457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 11s 6ms/step - loss: 2.0125 - accuracy: 0.3005\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7421 - accuracy: 0.3751\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6894 - accuracy: 0.3988\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6500 - accuracy: 0.4120\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6286 - accuracy: 0.4180\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6062 - accuracy: 0.4253\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5879 - accuracy: 0.4356\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5711 - accuracy: 0.4407\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5605 - accuracy: 0.4468\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5529 - accuracy: 0.4477\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5381 - accuracy: 0.4537\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5297 - accuracy: 0.4553\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5301 - accuracy: 0.4570\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5226 - accuracy: 0.4583\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5199 - accuracy: 0.4596\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5030 - accuracy: 0.4639\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5058 - accuracy: 0.4621\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4992 - accuracy: 0.4657\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4948 - accuracy: 0.4678\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4885 - accuracy: 0.4715\n",
            "INFO:tensorflow:Assets written to: ./my_models/dropout_model_drate_0.4/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.3287 - accuracy: 0.5311 - 1s/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.5310999751091003\n"
          ]
        }
      ],
      "source": [
        "# rate = 0.4\n",
        "model = create_model(dropout_rate=0.4)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "\n",
        "model.save('./my_models/dropout_model_drate_0.4')\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7dgiEewrILF"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Increasing the rate of the Dropout layer, caused the accuracy to decrease during the trainign and in the test set, compared to the first one. But still the test accuracy is better than the training accuracy (0.53 > 0.47)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-8w_Nr-sAxC",
        "outputId": "ccf5c268-2b82-4d3a-9aad-1d465e83c24a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 11s 6ms/step - loss: 1.9320 - accuracy: 0.3223\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6900 - accuracy: 0.3947\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6278 - accuracy: 0.4215\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5898 - accuracy: 0.4316\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5549 - accuracy: 0.4471\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5369 - accuracy: 0.4517\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5181 - accuracy: 0.4578\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4996 - accuracy: 0.4667\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4935 - accuracy: 0.4670\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4726 - accuracy: 0.4751\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4628 - accuracy: 0.4828\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4529 - accuracy: 0.4818\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4466 - accuracy: 0.4867\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4365 - accuracy: 0.4885\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4307 - accuracy: 0.4905\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4205 - accuracy: 0.4958\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4102 - accuracy: 0.4991\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4073 - accuracy: 0.4982\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4054 - accuracy: 0.5010\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3982 - accuracy: 0.5042\n",
            "INFO:tensorflow:Assets written to: ./my_models/dropout_model_rate_0.3/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 1.2823 - accuracy: 0.5430 - 1s/epoch - 3ms/step\n",
            "\n",
            "Test accuracy: 0.5429999828338623\n"
          ]
        }
      ],
      "source": [
        "# rate = 0.3\n",
        "model = create_model(dropout_rate=0.3)\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "model.save('./my_models/dropout_model_rate_0.3')\n",
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKmr6M3Js6NK"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Decreasing the rate to 0.3, gave better results in the test set: 0.54 compared to 0.53 of accuracy with rate  0.4.\n",
        "\n",
        "However the difference between the accuracy in training and test is bigger with rate 0.4 : 0.53 - 0.47 =0.06 \n",
        "\n",
        "with rate 0.3 : 0.54 - 0.5 = 0.04\n",
        "\n",
        "with rate 0.2 : 0.55 - 0.53 = 0.02\n",
        "\n",
        "Therefore the best rate is 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdyDpZgaqJli"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZkBwzPX_eHh"
      },
      "source": [
        "## Trying different model's parameters\n",
        "1. Try changing the number of layers, the number of hidden neurons in each layer, the activation functions, the weight initialization method...\n",
        "2. Compare the results you got for each evaluated model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlCohyURETzO"
      },
      "source": [
        "### Changing the number of Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXtHgGpjFm9i",
        "outputId": "13a11561-1c07-4856-e7e9-52eff3eb7604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 12s 6ms/step - loss: 1.9481 - accuracy: 0.3070\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7270 - accuracy: 0.3826\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6645 - accuracy: 0.4090\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6198 - accuracy: 0.4254\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5836 - accuracy: 0.4408\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5600 - accuracy: 0.4496\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5296 - accuracy: 0.4594\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5125 - accuracy: 0.4675\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4990 - accuracy: 0.4713\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4800 - accuracy: 0.4786\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4639 - accuracy: 0.4873\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4516 - accuracy: 0.4898\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4389 - accuracy: 0.4964\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4292 - accuracy: 0.4986\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4148 - accuracy: 0.5034\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4085 - accuracy: 0.5044\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3993 - accuracy: 0.5090\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3932 - accuracy: 0.5124\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3804 - accuracy: 0.5174\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3761 - accuracy: 0.5202\n",
            "313/313 - 1s - loss: 1.2442 - accuracy: 0.5577 - 822ms/epoch - 3ms/step\n",
            "Test accuracy : 0.557699978351593\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_elu_relu_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=5,nb_neurones=[512,264,132,128,10],\n",
        "                     activation_functions=[\"elu\",\"relu\",\"elu\",\"relu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\"])\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_elu_relu_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhuXZM-Nx55q",
        "outputId": "48a0a80d-ae69-4037-9985-fb4f24ade882"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9838 - accuracy: 0.2884\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.7483 - accuracy: 0.3747\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6789 - accuracy: 0.4028\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6331 - accuracy: 0.4202\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6032 - accuracy: 0.4323\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5651 - accuracy: 0.4455\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5483 - accuracy: 0.4541\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5222 - accuracy: 0.4640\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5060 - accuracy: 0.4705\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4940 - accuracy: 0.4756\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4727 - accuracy: 0.4776\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4603 - accuracy: 0.4853\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4426 - accuracy: 0.4935\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4353 - accuracy: 0.4951\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4240 - accuracy: 0.5000\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4159 - accuracy: 0.5012\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4011 - accuracy: 0.5081\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4014 - accuracy: 0.5080\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3936 - accuracy: 0.5134\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3779 - accuracy: 0.5167\n",
            "313/313 - 1s - loss: 1.2445 - accuracy: 0.5554 - 784ms/epoch - 3ms/step\n",
            "Test accuracy : 0.555400013923645\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_relu_model/assets\n"
          ]
        }
      ],
      "source": [
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=5,nb_neurones=[512,264,132,128,10],\n",
        "                     activation_functions=[\"relu\",\"relu\",\"relu\",\"relu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\"])\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_relu_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Gbmaj7zio_",
        "outputId": "5e904878-2868-4662-c350-af3d88368193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9228 - accuracy: 0.3169\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7092 - accuracy: 0.3879\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6430 - accuracy: 0.4153\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5964 - accuracy: 0.4316\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5687 - accuracy: 0.4442\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5437 - accuracy: 0.4531\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5212 - accuracy: 0.4624\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4991 - accuracy: 0.4712\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4786 - accuracy: 0.4789\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4671 - accuracy: 0.4830\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4487 - accuracy: 0.4899\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4335 - accuracy: 0.4969\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4273 - accuracy: 0.4976\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4138 - accuracy: 0.5043\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4008 - accuracy: 0.5069\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3966 - accuracy: 0.5116\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3893 - accuracy: 0.5138\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3831 - accuracy: 0.5171\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3742 - accuracy: 0.5195\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3598 - accuracy: 0.5241\n",
            "313/313 - 1s - loss: 1.2305 - accuracy: 0.5646 - 798ms/epoch - 3ms/step\n",
            "Test accuracy : 0.5645999908447266\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_elu_model/assets\n"
          ]
        }
      ],
      "source": [
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=5,nb_neurones=[512,264,132,128,10],\n",
        "                     activation_functions=[\"elu\",\"elu\",\"elu\",\"elu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\"])\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_elu_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ZQi8dkPnJG"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using elu activation function with Lecun initialization gave better results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsgy75Sx02iv",
        "outputId": "3dc38f4a-fcec-4679-ba90-d83bc87839b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 10s 5ms/step - loss: 1.9284 - accuracy: 0.3120\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7145 - accuracy: 0.3879\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6478 - accuracy: 0.4154\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.6093 - accuracy: 0.4296\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5703 - accuracy: 0.4442\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.5389 - accuracy: 0.4568\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5203 - accuracy: 0.4632\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4996 - accuracy: 0.4694\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4873 - accuracy: 0.4748\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4665 - accuracy: 0.4823\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4475 - accuracy: 0.4923\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4443 - accuracy: 0.4908\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4358 - accuracy: 0.4954\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4197 - accuracy: 0.5009\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4035 - accuracy: 0.5088\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3965 - accuracy: 0.5084\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3868 - accuracy: 0.5129\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3765 - accuracy: 0.5177\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3696 - accuracy: 0.5187\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3658 - accuracy: 0.5230\n",
            "313/313 - 1s - loss: 1.2308 - accuracy: 0.5606 - 798ms/epoch - 3ms/step\n",
            "Test accuracy : 0.5605999827384949\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_selu_model/assets\n"
          ]
        }
      ],
      "source": [
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=5,nb_neurones=[512,264,132,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\",\"lecun_uniform\"])\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_selu_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFxm-lg_6wU-",
        "outputId": "5f0f4d8b-de19-458c-e72f-e423a639b7e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 21s 10ms/step - loss: 1.9797 - accuracy: 0.2906\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.7554 - accuracy: 0.3712\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.6895 - accuracy: 0.3976\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.6444 - accuracy: 0.4182\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.6098 - accuracy: 0.4292\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5841 - accuracy: 0.4425\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5545 - accuracy: 0.4537\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5320 - accuracy: 0.4601\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5207 - accuracy: 0.4669\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5050 - accuracy: 0.4743\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4842 - accuracy: 0.4777\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4668 - accuracy: 0.4867\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4585 - accuracy: 0.4901\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4478 - accuracy: 0.4921\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4316 - accuracy: 0.4985\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4288 - accuracy: 0.5028\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4149 - accuracy: 0.5058\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4070 - accuracy: 0.5094\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.4004 - accuracy: 0.5121\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3909 - accuracy: 0.5167\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3837 - accuracy: 0.5187\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3712 - accuracy: 0.5236\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3747 - accuracy: 0.5212\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3672 - accuracy: 0.5278\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3552 - accuracy: 0.5298\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3514 - accuracy: 0.5314\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3438 - accuracy: 0.5322\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3355 - accuracy: 0.5337\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3293 - accuracy: 0.5373\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.3302 - accuracy: 0.5373\n",
            "313/313 - 1s - loss: 1.2078 - accuracy: 0.5695 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.5695000290870667\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_7layers_selu_lecun_normal_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Changing the number of layers and number of epochs\n",
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=7,nb_neurones=[512,464,312,264,132,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"])\n",
        "model.fit(x_train,y_train,epochs=30)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_7layers_selu_lecun_normal_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRyfLgt3iVRn"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Increasing the number of layers and epochs didn't help improving the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT3GVUeE_aZh",
        "outputId": "78122e15-d720-433c-f5ae-d23f18d29492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 17s 8ms/step - loss: 2.0764 - accuracy: 0.2382\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8917 - accuracy: 0.3090\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8499 - accuracy: 0.3259\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8214 - accuracy: 0.3421\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7967 - accuracy: 0.3531\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 1.7817 - accuracy: 0.3603\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7654 - accuracy: 0.3656\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7546 - accuracy: 0.3725\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7498 - accuracy: 0.3745\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7407 - accuracy: 0.3758\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7295 - accuracy: 0.3864\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7266 - accuracy: 0.3835\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7190 - accuracy: 0.3870\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7153 - accuracy: 0.3906\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7062 - accuracy: 0.3931\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7100 - accuracy: 0.3958\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7019 - accuracy: 0.3971\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.7003 - accuracy: 0.3963\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6937 - accuracy: 0.3987\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6897 - accuracy: 0.4003\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6917 - accuracy: 0.3997\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 13s 9ms/step - loss: 1.6898 - accuracy: 0.4002\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6840 - accuracy: 0.4047\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6892 - accuracy: 0.4023\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6843 - accuracy: 0.4015\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6759 - accuracy: 0.4083\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6795 - accuracy: 0.4067\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6753 - accuracy: 0.4084\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6750 - accuracy: 0.4078\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.6696 - accuracy: 0.4101\n",
            "313/313 - 1s - loss: 1.4662 - accuracy: 0.4818 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.48179998993873596\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_6layers_selu_lecun_normal_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Changing the number of layers and number of neurones\n",
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=6,nb_neurones=[64,64,64,64,64,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"])\n",
        "model.fit(x_train,y_train,epochs=30)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_6layers_selu_lecun_normal_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6nQG9yNCSfc",
        "outputId": "83669f60-73f1-4f29-88dd-36a3b153f2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 16s 9ms/step - loss: 2.1890 - accuracy: 0.2402\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.8276 - accuracy: 0.3388\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.7480 - accuracy: 0.3742\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.7005 - accuracy: 0.3928\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.6616 - accuracy: 0.4102\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.6276 - accuracy: 0.4246\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.6015 - accuracy: 0.4349\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5783 - accuracy: 0.4440\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5565 - accuracy: 0.4516\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5408 - accuracy: 0.4596\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5292 - accuracy: 0.4645\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5138 - accuracy: 0.4670\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5036 - accuracy: 0.4698\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4888 - accuracy: 0.4786\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4757 - accuracy: 0.4817\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4671 - accuracy: 0.4838\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4604 - accuracy: 0.4888\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4475 - accuracy: 0.4912\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4442 - accuracy: 0.4926\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4339 - accuracy: 0.4977\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4351 - accuracy: 0.4980\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4219 - accuracy: 0.5011\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.4144 - accuracy: 0.5051\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4136 - accuracy: 0.5067\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4092 - accuracy: 0.5061\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4021 - accuracy: 0.5094\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3968 - accuracy: 0.5128\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3912 - accuracy: 0.5111\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3917 - accuracy: 0.5132\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3761 - accuracy: 0.5196\n",
            "313/313 - 1s - loss: 1.2335 - accuracy: 0.5596 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.5595999956130981\n",
            "INFO:tensorflow:Assets written to: ./my_models/training5_6layers2_selu_lecun_normal_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Changing the number of layers and number of neurones\n",
        "model = create_model(dropout_rate=0.4,\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"softmax\"],\n",
        "                     weight_initializations=[\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\"])\n",
        "model.fit(x_train,y_train,epochs=30)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training5_6layers2_selu_lecun_normal_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg2e5dtMG3LB"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Despite all the changes, the accuracy is still low.\n",
        "\n",
        "We noticed that the accuracy was better when using ReLU alongside with He intialization function.\n",
        "\n",
        "When increasing the number of layers, the accuracy didn't improve. In addition we noticed that using the same number of neurones in all layers gave us a bad accuracy, compared to the models where we used a different number of neurones in each layer.\n",
        "\n",
        "Therefore untill now the best model is the one using 3 layers with relu activation functions, He initialization method, with BatchNormalization layers being used before each layer and using a rate= 0.4 for the Dropout Layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc8lCKMlGMrb"
      },
      "source": [
        "## Few more experiments to go\n",
        "\n",
        "1.   **Exploring more regularization techniques:** Try at least 2 regularization techniques separately and combined.  A non-exhaustive list of regularization techniques you can test\n",
        "\n",
        "\n",
        "> * L1 and L2 regularization\n",
        "* Early stopping\n",
        "* Data augmentation\n",
        "* Decreasing the complexity of the model\n",
        "\n",
        "2.   **Hyperparameters' tuning:** Try to tune the learning parameters using the tuning strategies we learned about:\n",
        "\n",
        "> * Learning rate\n",
        "* Mini-batch size\n",
        "* The optimizer and its parameters\n",
        "\n",
        "3. Analyze the impact of each of the applied techniques. What were the most effective ones? What were the hypeparameters that affects the results the most?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkp1pOo6IOIK"
      },
      "source": [
        "####1. Exploring Regularization techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBXIjaAVGMPd",
        "outputId": "b990b072-d124-4985-adae-1d18227d8ff3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 22s 11ms/step - loss: 34.6224 - accuracy: 0.1683\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 7.0282 - accuracy: 0.1768\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 6.7047 - accuracy: 0.1634\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 6.4354 - accuracy: 0.1629\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 6.1622 - accuracy: 0.1614\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 5.8900 - accuracy: 0.1675\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 5.5946 - accuracy: 0.1643\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 5.5339 - accuracy: 0.1692\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 5.3350 - accuracy: 0.1667\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 5.1479 - accuracy: 0.1642\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 5.0062 - accuracy: 0.1663\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.8592 - accuracy: 0.1674\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.7750 - accuracy: 0.1669\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.6634 - accuracy: 0.1671\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.6090 - accuracy: 0.1646\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.5035 - accuracy: 0.1645\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 4.4615 - accuracy: 0.1654\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 4.3795 - accuracy: 0.1658\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3957 - accuracy: 0.1681\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3308 - accuracy: 0.1681\n",
            "313/313 - 1s - loss: 4.1873 - accuracy: 0.1685 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.16850000619888306\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L1_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# L1\n",
        "model = create_model(dropout_rate = 0.4,\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"softmax\"],\n",
        "                     weight_initializations=[\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\",\"he_normal\"],\n",
        "                     regularizer=L1(0.01)\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L1_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1IxVuxvWqqO"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using Dropout and L1 regularization gave bad result. Maybe we should be removing the Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIK-spj-XBc0",
        "outputId": "2b86b873-b24e-4c17-c6af-9362294185d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 18s 10ms/step - loss: 11.2504 - accuracy: 0.1676\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.7247 - accuracy: 0.1960\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 4.3952 - accuracy: 0.2291\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 4.1027 - accuracy: 0.2352\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.9520 - accuracy: 0.2407\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.7763 - accuracy: 0.2441\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.7164 - accuracy: 0.2447\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.6410 - accuracy: 0.2448\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.5986 - accuracy: 0.2462\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.5700 - accuracy: 0.2481\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.5427 - accuracy: 0.2503\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.5090 - accuracy: 0.2490\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4879 - accuracy: 0.2472\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4767 - accuracy: 0.2512\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4581 - accuracy: 0.2506\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.4466 - accuracy: 0.2511\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.4439 - accuracy: 0.2489\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4447 - accuracy: 0.2518\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 3.4386 - accuracy: 0.2518\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 3.4341 - accuracy: 0.2506\n",
            "313/313 - 1s - loss: 3.4162 - accuracy: 0.2566 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.2565999925136566\n",
            "INFO:tensorflow:Assets written to: ./my_models/training6_L1_model_/assets\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "# L1\n",
        "model = create_model(dropout_rate=0,\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L1(0.01)\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('./my_models/training6_L1_model_')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AEKAbCLcYLL"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "The accuracy is bad despite removing the Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXJgNQotdVkW",
        "outputId": "4bb874dc-4dbf-41e0-8a85-71c9c6870016"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 19s 11ms/step - loss: 3.9734 - accuracy: 0.2694\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3216 - accuracy: 0.2689\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3258 - accuracy: 0.2665\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.3104 - accuracy: 0.2618\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2878 - accuracy: 0.2683\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2642 - accuracy: 0.2738\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.2307 - accuracy: 0.2764\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.2048 - accuracy: 0.2778\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1882 - accuracy: 0.2801\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1745 - accuracy: 0.2826\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1623 - accuracy: 0.2816\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1573 - accuracy: 0.2825\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1509 - accuracy: 0.2839\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1412 - accuracy: 0.2860\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1338 - accuracy: 0.2888\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1326 - accuracy: 0.2888\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1279 - accuracy: 0.2853\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 16s 11ms/step - loss: 2.1233 - accuracy: 0.2868\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1149 - accuracy: 0.2902\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.1162 - accuracy: 0.2920\n",
            "313/313 - 2s - loss: 2.0482 - accuracy: 0.3110 - 2s/epoch - 5ms/step\n",
            "Test accuracy : 0.3109999895095825\n",
            "INFO:tensorflow:Assets written to: ./my_models/training6_L2_model/assets\n"
          ]
        }
      ],
      "source": [
        "# L2\n",
        "model = create_model(\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L2_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3QgjZ0zezTU"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using L2 regularization technique improved the accuracy compared to the previous technique. However it is still bad compared to when using Dropout Layer only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5fgylQIfR8y",
        "outputId": "90441c88-1789-4954-9030-202e1e4807fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 17s 9ms/step - loss: 1.8942 - accuracy: 0.3223\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 15s 10ms/step - loss: 1.6785 - accuracy: 0.4017\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.6111 - accuracy: 0.4264\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 1.5640 - accuracy: 0.4466\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.5292 - accuracy: 0.4582\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.5013 - accuracy: 0.4690\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.4753 - accuracy: 0.4791\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4573 - accuracy: 0.4830\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4317 - accuracy: 0.4980\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4130 - accuracy: 0.4991\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3995 - accuracy: 0.5060\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3833 - accuracy: 0.5138\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3672 - accuracy: 0.5167\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3578 - accuracy: 0.5243\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3470 - accuracy: 0.5321\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.3384 - accuracy: 0.5310\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.3245 - accuracy: 0.5351\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3118 - accuracy: 0.5404\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3107 - accuracy: 0.5420\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 15s 9ms/step - loss: 1.2993 - accuracy: 0.5463\n",
            "313/313 - 1s - loss: 1.2286 - accuracy: 0.5584 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.5583999752998352\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L1L2_model/assets\n"
          ]
        }
      ],
      "source": [
        "# L1L2\n",
        "model = create_model(\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L1L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L1L2_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5Fng9ophtOy"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using L1L2 regularizer with Dropout gaved better results than L1 or L2 regularizers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyXNVi42iEW1",
        "outputId": "7d3abaa8-5575-4fc8-9f71-e1193de1718b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 19s 11ms/step - loss: 3.9329 - accuracy: 0.2686\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3281 - accuracy: 0.2650\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3431 - accuracy: 0.2689\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3319 - accuracy: 0.2694\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3089 - accuracy: 0.2755\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2802 - accuracy: 0.2839\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2434 - accuracy: 0.2876\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2157 - accuracy: 0.2852\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1942 - accuracy: 0.2909\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1768 - accuracy: 0.2962\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1707 - accuracy: 0.2970\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1615 - accuracy: 0.2980\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1538 - accuracy: 0.2984\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1479 - accuracy: 0.2986\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1418 - accuracy: 0.3000\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1347 - accuracy: 0.3006\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1315 - accuracy: 0.3008\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1228 - accuracy: 0.3035\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1178 - accuracy: 0.3062\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1178 - accuracy: 0.3047\n",
            "313/313 - 1s - loss: 2.0348 - accuracy: 0.3054 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.305400013923645\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L2_early_stopping_model/assets\n"
          ]
        }
      ],
      "source": [
        "# L1L2 with early stopping\n",
        "early_stopping = EarlyStopping(monitor=\"accuracy\",patience=3,verbose=2,restore_best_weights= True)\n",
        "model = create_model(\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20,callbacks=[early_stopping])\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_L2_early_stopping_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-OE8QAoxOWH"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using early stopping with L1L2 regularization and Dropout didn't give much good results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgmbkm-9YkMQ",
        "outputId": "25d844d7-8021-422a-9cfe-1d4c5b170954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 26s 14ms/step - loss: 4.0229 - accuracy: 0.2110\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 2.3638 - accuracy: 0.2156\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3774 - accuracy: 0.2159\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3726 - accuracy: 0.2163\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3640 - accuracy: 0.2204\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3506 - accuracy: 0.2229\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.3310 - accuracy: 0.2232\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 2.3067 - accuracy: 0.2249\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 2.2858 - accuracy: 0.2275\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2779 - accuracy: 0.2281\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2645 - accuracy: 0.2294\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2571 - accuracy: 0.2332\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 23s 15ms/step - loss: 2.2524 - accuracy: 0.2343\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2456 - accuracy: 0.2363\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2412 - accuracy: 0.2359\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2359 - accuracy: 0.2385\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2329 - accuracy: 0.2384\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2311 - accuracy: 0.2396\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2214 - accuracy: 0.2425\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 2.2187 - accuracy: 0.2380\n",
            "313/313 - 1s - loss: 2.1727 - accuracy: 0.2605 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.2605000138282776\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_data_aug_model/assets\n"
          ]
        }
      ],
      "source": [
        "# Using data augmentation technique with L1L2 regularizer\n",
        "data_augmentation = Sequential([\n",
        "  Rescaling(1./255),\n",
        "  RandomFlip(\"horizontal_and_vertical\"),\n",
        "  RandomRotation(0.2),\n",
        "  RandomContrast(0.3), \n",
        "  RandomZoom(0.2)\n",
        "\n",
        "])\n",
        "\n",
        "model = create_model(\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2(),\n",
        "                     data_augmentation= data_augmentation\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training6_data_aug_model')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QacVSnP4c7E2"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using data augmentation techniques reduced the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlcFzrPydSVE"
      },
      "source": [
        "#### Hyperparameters' tuning \n",
        "\n",
        "* Mini-batch size\n",
        "* The optimizer and its parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt8RB63qdR-u",
        "outputId": "084197fd-fdeb-4194-e92d-d3d9600dfbaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 23s 11ms/step - loss: 3.6305 - accuracy: 0.1901\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.0608 - accuracy: 0.1941\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 2.7987 - accuracy: 0.1968\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.6765 - accuracy: 0.1999\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.6213 - accuracy: 0.2042\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.6248 - accuracy: 0.1999\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5835 - accuracy: 0.1999\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5681 - accuracy: 0.2013\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5782 - accuracy: 0.2029\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.5672 - accuracy: 0.2016\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5417 - accuracy: 0.2014\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.5159 - accuracy: 0.2025\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5125 - accuracy: 0.2025\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5380 - accuracy: 0.2018\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5379 - accuracy: 0.1986\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5108 - accuracy: 0.1996\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4926 - accuracy: 0.2027\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.5078 - accuracy: 0.2040\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5104 - accuracy: 0.2057\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4902 - accuracy: 0.2073\n",
            "313/313 - 1s - loss: 2.4705 - accuracy: 0.2035 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.20350000262260437\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.01_model/assets\n"
          ]
        }
      ],
      "source": [
        "#  Learning rate\n",
        "model = create_model(optimizer=Adam(learning_rate=0.01),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.01_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T67cEQnNhbCq",
        "outputId": "5d99cea4-a929-42c6-b5e9-2a8c78c118e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 20s 11ms/step - loss: 11.9851 - accuracy: 0.1420\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 12.1914 - accuracy: 0.1407\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 14.1275 - accuracy: 0.1416\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 15.2132 - accuracy: 0.1384\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 15.5070 - accuracy: 0.1405\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 13.8639 - accuracy: 0.1389\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 12.9806 - accuracy: 0.1469\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 13.6904 - accuracy: 0.1419\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 12.7134 - accuracy: 0.1436\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 12.4823 - accuracy: 0.1427\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 12.6228 - accuracy: 0.1410\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 11.9834 - accuracy: 0.1476\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 12.6029 - accuracy: 0.1461\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 13.5649 - accuracy: 0.1449\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 12.6387 - accuracy: 0.1441\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 13.1442 - accuracy: 0.1445\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 10.5236 - accuracy: 0.1464\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 10.7687 - accuracy: 0.1479\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 10.5038 - accuracy: 0.1454\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 21.5910 - accuracy: 0.1490\n",
            "313/313 - 1s - loss: 8.0597 - accuracy: 0.1221 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.12210000306367874\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.08_model/assets\n"
          ]
        }
      ],
      "source": [
        "#  Learning rate\n",
        "model = create_model(optimizer=Adam(learning_rate=0.08),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.08_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMKAk8XU7bkJ"
      },
      "source": [
        "**Analysis :**\n",
        "\n",
        "Using higher values of learning rate makes the training faster, however it gives a bad accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypwlf-Yr7rYh",
        "outputId": "7d365958-3912-42ab-974e-1eaf66d64a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 20s 11ms/step - loss: 11.1406 - accuracy: 0.2589\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 6.6103 - accuracy: 0.3207\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 4.1748 - accuracy: 0.3472\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 3.0359 - accuracy: 0.3631\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 2.5008 - accuracy: 0.3729\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 2.2271 - accuracy: 0.3797\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0795 - accuracy: 0.3866\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9939 - accuracy: 0.3924\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9405 - accuracy: 0.3972\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9055 - accuracy: 0.3998\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8857 - accuracy: 0.4036\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8694 - accuracy: 0.4058\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8594 - accuracy: 0.4104\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8476 - accuracy: 0.4130\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8403 - accuracy: 0.4161\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8362 - accuracy: 0.4183\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8309 - accuracy: 0.4221\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8244 - accuracy: 0.4220\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8256 - accuracy: 0.4224\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8223 - accuracy: 0.4228\n",
            "313/313 - 1s - loss: 1.6892 - accuracy: 0.4679 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.46790000796318054\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.0001_model/assets\n"
          ]
        }
      ],
      "source": [
        "#  Learning rate\n",
        "model = create_model(optimizer=Adam(learning_rate=0.0001),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_lr_0.0001_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIS-8QaE9czA"
      },
      "source": [
        "**Analysis :**\n",
        "using low learning rates leads to longer training, however it gaved better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44mpytXkhh06",
        "outputId": "da313e8a-bd21-4251-b576-dfdee2e98f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 19s 11ms/step - loss: 4.3878 - accuracy: 0.2575\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3845 - accuracy: 0.2704\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4045 - accuracy: 0.2604\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4019 - accuracy: 0.2590\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3818 - accuracy: 0.2593\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3643 - accuracy: 0.2650\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3424 - accuracy: 0.2644\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3191 - accuracy: 0.2663\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2996 - accuracy: 0.2697\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2743 - accuracy: 0.2706\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2601 - accuracy: 0.2751\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2498 - accuracy: 0.2751\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2384 - accuracy: 0.2776\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2309 - accuracy: 0.2788\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2298 - accuracy: 0.2785\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2161 - accuracy: 0.2805\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2096 - accuracy: 0.2823\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2102 - accuracy: 0.2783\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2032 - accuracy: 0.2799\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1984 - accuracy: 0.2757\n",
            "313/313 - 1s - loss: 2.1274 - accuracy: 0.3067 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.3066999912261963\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.8_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta1\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(learning_rate=0.001,beta_1=0.8),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.8_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpVWwtNRhwzm",
        "outputId": "60478dcc-dae9-4bee-957c-0d008f635d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 19s 11ms/step - loss: 4.2907 - accuracy: 0.2668\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4945 - accuracy: 0.2789\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5102 - accuracy: 0.2764\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.5240 - accuracy: 0.2802\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5109 - accuracy: 0.2808\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.5043 - accuracy: 0.2847\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 16s 10ms/step - loss: 2.4918 - accuracy: 0.2886\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4720 - accuracy: 0.2897\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4631 - accuracy: 0.2917\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4428 - accuracy: 0.2914\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4178 - accuracy: 0.2962\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4067 - accuracy: 0.2948\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3920 - accuracy: 0.2946\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3751 - accuracy: 0.2953\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3586 - accuracy: 0.2939\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3523 - accuracy: 0.2962\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3348 - accuracy: 0.2990\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3265 - accuracy: 0.2975\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3255 - accuracy: 0.2989\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3116 - accuracy: 0.2982\n",
            "313/313 - 1s - loss: 2.2290 - accuracy: 0.3352 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.3352000117301941\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.99_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta1\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(learning_rate=0.001,beta_1=0.99),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.99_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejlTrn-hFmtf",
        "outputId": "b48b93de-051f-465a-cbe2-2d4a1ac6ad86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 21s 11ms/step - loss: 4.3316 - accuracy: 0.2612\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.4012 - accuracy: 0.2657\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.4264 - accuracy: 0.2616\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 2.4000 - accuracy: 0.2609\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3914 - accuracy: 0.2589\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3801 - accuracy: 0.2644\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3573 - accuracy: 0.2686\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3277 - accuracy: 0.2695\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.3068 - accuracy: 0.2729\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2822 - accuracy: 0.2715\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2702 - accuracy: 0.2740\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2574 - accuracy: 0.2733\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2427 - accuracy: 0.2747\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2366 - accuracy: 0.2741\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2301 - accuracy: 0.2767\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 2.2227 - accuracy: 0.2795\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2192 - accuracy: 0.2751\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2105 - accuracy: 0.2790\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2101 - accuracy: 0.2760\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2043 - accuracy: 0.2773\n",
            "313/313 - 1s - loss: 2.0962 - accuracy: 0.3214 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.321399986743927\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.9_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta1\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta1_0.9_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-M3SN9dKwD-"
      },
      "source": [
        "**Analysis :**\n",
        "The higher the beta1 the better"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Hyv8-FRh_fX",
        "outputId": "cc0ec216-1c6f-4073-8fe2-a9b903ed431f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 26s 15ms/step - loss: 11.2811 - accuracy: 0.2213\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 6.6087 - accuracy: 0.2902\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 4.2192 - accuracy: 0.3155\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.1002 - accuracy: 0.3365\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 2.5523 - accuracy: 0.3509\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 2.2766 - accuracy: 0.3568\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1238 - accuracy: 0.3648\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0370 - accuracy: 0.3715\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9861 - accuracy: 0.3784\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9578 - accuracy: 0.3797\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 1.9328 - accuracy: 0.3853\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 1.9227 - accuracy: 0.3860\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9128 - accuracy: 0.3904\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9067 - accuracy: 0.3892\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8989 - accuracy: 0.3927\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.8977 - accuracy: 0.3954\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8927 - accuracy: 0.3964\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8867 - accuracy: 0.3980\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8864 - accuracy: 0.4016\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8855 - accuracy: 0.4003\n",
            "313/313 - 1s - loss: 1.7466 - accuracy: 0.4427 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.44269999861717224\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.9_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta2\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(learning_rate=0.0001,beta_2=0.9),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.9_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCN0Wo55iGgT",
        "outputId": "ac457adf-33de-44f0-b1b6-dba638398a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 21s 12ms/step - loss: 11.0942 - accuracy: 0.2220\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 6.1678 - accuracy: 0.2885\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 3.8667 - accuracy: 0.3186\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.8811 - accuracy: 0.3380\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4217 - accuracy: 0.3506\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 2.1950 - accuracy: 0.3592\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0767 - accuracy: 0.3637\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0137 - accuracy: 0.3701\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9765 - accuracy: 0.3762\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9565 - accuracy: 0.3748\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9395 - accuracy: 0.3788\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9265 - accuracy: 0.3832\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9228 - accuracy: 0.3856\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9122 - accuracy: 0.3856\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9061 - accuracy: 0.3896\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9050 - accuracy: 0.3931\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9035 - accuracy: 0.3923\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9022 - accuracy: 0.3953\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9027 - accuracy: 0.3941\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.8952 - accuracy: 0.3987\n",
            "313/313 - 1s - loss: 1.7508 - accuracy: 0.4492 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.44920000433921814\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.7_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta2\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(learning_rate=0.0001,beta_2=0.7),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.7_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MVpqv5CiJRX",
        "outputId": "2c69e439-a251-4d5a-88bc-b01956b6e9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 19s 11ms/step - loss: 11.7245 - accuracy: 0.2220\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 7.6423 - accuracy: 0.2824\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 5.0746 - accuracy: 0.3123\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 3.6369 - accuracy: 0.3318\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.8558 - accuracy: 0.3440\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.4475 - accuracy: 0.3543\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.2281 - accuracy: 0.3610\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.1005 - accuracy: 0.3672\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 2.0332 - accuracy: 0.3695\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9933 - accuracy: 0.3715\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9685 - accuracy: 0.3751\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9511 - accuracy: 0.3806\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9422 - accuracy: 0.3815\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9375 - accuracy: 0.3818\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 18s 11ms/step - loss: 1.9303 - accuracy: 0.3832\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9248 - accuracy: 0.3880\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9221 - accuracy: 0.3890\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9185 - accuracy: 0.3902\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9145 - accuracy: 0.3937\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 17s 11ms/step - loss: 1.9127 - accuracy: 0.3956\n",
            "313/313 - 1s - loss: 1.7499 - accuracy: 0.4632 - 1s/epoch - 4ms/step\n",
            "Test accuracy : 0.46320000290870667\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.9999_model/assets\n"
          ]
        }
      ],
      "source": [
        "# beta2\n",
        "model = create_model(dropout_rate=0.4,optimizer=Adam(learning_rate=0.0001,beta_2=0.9999),\n",
        "                     nb_layers=6,nb_neurones=[364,264,228,164,128,10],\n",
        "                     activation_functions=[\"selu\",\"selu\",\"selu\",\"selu\",\"selu\",\"softmax\"],\n",
        "                     weight_initializations=[\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\",\"lecun_normal\"],\n",
        "                     regularizer=L2()\n",
        "                     )\n",
        "model.fit(x_train,y_train,epochs=20)\n",
        "loss_test, accuracy_test = model.evaluate(x_test,y_test,verbose=2)\n",
        "\n",
        "print(f\"Test accuracy : {accuracy_test}\")\n",
        "model.save('/content/drive/MyDrive/Colab_Notebooks/Project4/models/training7_beta2_0.9999_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_Jcwr-liOQf"
      },
      "source": [
        "**Analysis :**\n",
        "The closest Beta2 to 1 the better the results. As we can see when using beta2 = 0.9999, the accuracy in the test set improved and even the overfitting has been reduced largely (0.46 - 0.39 = 0.07) compared to other methods ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcFRgyd_TAOx"
      },
      "source": [
        "## Answer the following questions\n",
        "*Hint: Do your own research to answer these questions, none of the questions is answered in the previous lessons*\n",
        "\n",
        "\n",
        "1.   Why we cant reach a good accuracy on this task?\n",
        "2.   Explain why fully connected neural networks are Not efficient on image tasks\n",
        "3.   What architecture can be used  for such tasks? Why they are more adapted for that?\n",
        "\n",
        "\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVwMF-0CSWpb",
        "outputId": "6ef15700-6357-4f45-92ad-24ec2f9067a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " batch_normalization_72 (Bat  (None, 3072)             12288     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 364)               1118572   \n",
            "                                                                 \n",
            " batch_normalization_73 (Bat  (None, 364)              1456      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 364)               0         \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 264)               96360     \n",
            "                                                                 \n",
            " batch_normalization_74 (Bat  (None, 264)              1056      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 264)               0         \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 228)               60420     \n",
            "                                                                 \n",
            " batch_normalization_75 (Bat  (None, 228)              912       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 228)               0         \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 164)               37556     \n",
            "                                                                 \n",
            " batch_normalization_76 (Bat  (None, 164)              656       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 164)               0         \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 128)               21120     \n",
            "                                                                 \n",
            " batch_normalization_77 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,352,198\n",
            "Trainable params: 1,343,758\n",
            "Non-trainable params: 8,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mln2PBKOSH_r"
      },
      "source": [
        "\n",
        "\n",
        "1.   Why we cant reach a good accuracy on this task?\n",
        "\n",
        "*   There is more than 1 million trainable parameters\n",
        "\n",
        "\n",
        "2.  Explain why fully connected neural networks are Not efficient on image tasks\n",
        "\n",
        "*   Flattening images causes the loss of spatial context and correlation between pixels\n",
        "*   The number of trainable parameters is huge causing overfitting\n",
        "*   Images may contain same features with different sizes at different places, it is impossible for a fully connected network to consider them the same.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Unit 4 Project - Questions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
